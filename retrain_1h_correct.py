"""
Retrain 1h model with CORRECT features that match the live bot
Uses the exact 17 features from live_demo_1h/features.py
"""
import pandas as pd
import numpy as np
from sklearn.ensemble import (
    RandomForestClassifier,
    ExtraTreesClassifier,
    GradientBoostingClassifier,
    HistGradientBoostingClassifier
)
from sklearn.linear_model import LogisticRegression
from sklearn.calibration import CalibratedClassifierCV
import joblib
import json
from datetime import datetime
import os
import math

print("=" * 80)
print("RETRAINING 1H MODEL WITH CORRECT FEATURES")
print("=" * 80)
print()

# ============================================
# STEP 1: LOAD DATA
# ============================================
print("ðŸ“‚ Step 1: Loading 1h data...")
print("-" * 80)

df = pd.read_csv('ohlc_btc_1h.csv')
df['timestamp'] = pd.to_datetime(df['timestamp'])
df = df.sort_values('timestamp').reset_index(drop=True)

print(f"âœ… Loaded {len(df)} candles")
print(f"   Date range: {df['timestamp'].min()} to {df['timestamp'].max()}")
print()

# ============================================
# STEP 2: CREATE THE EXACT 17 FEATURES
# ============================================
print("ðŸ”§ Step 2: Creating features (matching live bot exactly)...")
print("-" * 80)

def create_live_bot_features(df):
    """
    Create the exact 17 features that live_demo_1h/features.py uses
    """
    # Basic returns
    df['mom_1'] = df['close'].pct_change(1)
    df['mom_3'] = df['close'].pct_change(3)
    
    # EMA20
    df['ema20'] = df['close'].ewm(span=20, adjust=False).mean()
    
    # Realized volatility (12-period)
    df['rv_1h'] = df['mom_1'].rolling(12).apply(lambda x: np.sqrt(np.sum(x**2)), raw=True)
    
    # Mean reversion z-score
    df['mr_ema20_z'] = (df['close'] - df['ema20']) / (df['rv_1h'] + 1e-9)
    
    # Regime detection
    rv_median = df['rv_1h'].rolling(12).median()
    df['regime_high_vol'] = ((df['rv_1h'] > 2.0 * rv_median) & (df['rv_1h'] > 0)).astype(float)
    
    # Garman-Klass volatility
    def gk_vol(row):
        if row['open'] <= 0 or row['high'] <= 0 or row['low'] <= 0 or row['close'] <= 0:
            return 0.0
        try:
            return math.sqrt(
                0.5 * (math.log(row['high'] / row['low']) ** 2)
                - (2 * math.log(2) - 1) * (math.log(row['close'] / row['open']) ** 2)
            )
        except:
            return 0.0
    
    df['gk_volatility'] = df.apply(gk_vol, axis=1)
    
    # Jump magnitude
    df['jump_magnitude'] = df['mom_1'].abs()
    
    # Volume features
    df['volume_mean'] = df['volume'].rolling(50).mean()
    df['volume_intensity'] = (df['volume'] / (df['volume_mean'] + 1e-9)) - 1.0
    
    # Price range and efficiency
    df['price_range'] = (df['high'] - df['low']) / (df['close'] + 1e-9)
    df['price_efficiency'] = df['mom_1'].abs() / (df['price_range'] + 1e-9)
    
    # Price-volume correlation
    def price_volume_corr(idx, window=36):
        if idx < window:
            return 0.0
        returns = df['mom_1'].iloc[idx-window:idx].values
        volumes = df['volume'].iloc[idx-window:idx].values
        if len(returns) >= 3:
            try:
                return float(np.corrcoef(returns, volumes)[0, 1])
            except:
                return 0.0
        return 0.0
    
    df['price_volume_corr'] = [price_volume_corr(i) for i in range(len(df))]
    
    # VWAP momentum (proxy with mom_3)
    df['vwap_momentum'] = df['mom_3']
    
    # Depth proxy (not available, set to 0)
    df['depth_proxy'] = 0.0
    
    # Funding features (set to 0 for now - would need real funding data)
    df['funding_rate'] = 0.0
    df['funding_momentum_1h'] = 0.0
    
    # Flow diff (cohort signals - set to 0 for now)
    df['flow_diff'] = 0.0
    df['S_top'] = 0.0
    df['S_bot'] = 0.0
    
    return df

df = create_live_bot_features(df)

# The exact 17 features in the correct order
feature_columns = [
    "mom_1", "mom_3", "mr_ema20_z", "rv_1h", "regime_high_vol",
    "gk_volatility", "jump_magnitude", "volume_intensity",
    "price_efficiency", "price_volume_corr", "vwap_momentum",
    "depth_proxy", "funding_rate", "funding_momentum_1h",
    "flow_diff", "S_top", "S_bot"
]

print(f"âœ… Created {len(feature_columns)} features")
print(f"   Features: {', '.join(feature_columns[:5])}...")
print()

# ============================================
# STEP 3: CREATE TARGET
# ============================================
print("ðŸŽ¯ Step 3: Creating target variable...")
print("-" * 80)

df['future_return'] = df['close'].pct_change(1).shift(-1)

up_threshold = 0.005
down_threshold = -0.005

df['target'] = 1  # NEUTRAL
df.loc[df['future_return'] > up_threshold, 'target'] = 2  # UP
df.loc[df['future_return'] < down_threshold, 'target'] = 0  # DOWN

df = df.dropna()

print(f"âœ… Target distribution:")
target_counts = df['target'].value_counts().sort_index()
for label, count in target_counts.items():
    label_name = ['DOWN', 'NEUTRAL', 'UP'][label]
    pct = count / len(df) * 100
    print(f"   {label_name}: {count} ({pct:.1f}%)")
print()

# ============================================
# STEP 4: TRAIN/TEST SPLIT
# ============================================
print("ðŸ“Š Step 4: Preparing training/test split...")
print("-" * 80)

X = df[feature_columns]
y = df['target']

split_idx = int(len(df) * 0.8)
X_train, X_test = X[:split_idx], X[split_idx:]
y_train, y_test = y[:split_idx], y[split_idx:]

print(f"âœ… Training samples: {len(X_train)}")
print(f"âœ… Test samples: {len(X_test)}")
print()

# ============================================
# STEP 5: TRAIN MODELS
# ============================================
print("ðŸ¤– Step 5: Training base models...")
print("-" * 80)

models = {
    'randomforest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),
    'extratrees': ExtraTreesClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),
    'histgb': HistGradientBoostingClassifier(max_iter=100, random_state=42),
    'gb_classifier': GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42),
}

trained_models = {}
cv_scores = {}

for name, model in models.items():
    print(f"  Training {name}...", end=" ")
    model.fit(X_train, y_train)
    score = model.score(X_test, y_test)
    cv_scores[name] = float(score)
    trained_models[name] = model
    print(f"âœ… Accuracy: {score:.4f}")

print()

# ============================================
# STEP 6: META-CLASSIFIER
# ============================================
print("ðŸŽ¯ Step 6: Creating meta-classifier...")
print("-" * 80)

meta_features_train = []
meta_features_test = []

for name, model in trained_models.items():
    pred_train = model.predict_proba(X_train)
    pred_test = model.predict_proba(X_test)
    meta_features_train.append(pred_train)
    meta_features_test.append(pred_test)

X_meta_train = np.hstack(meta_features_train)
X_meta_test = np.hstack(meta_features_test)

meta_classifier = LogisticRegression(random_state=42, max_iter=1000)
meta_classifier.fit(X_meta_train, y_train)

meta_score = meta_classifier.score(X_meta_test, y_test)
print(f"âœ… Meta-classifier accuracy: {meta_score:.4f}")
print()

# ============================================
# STEP 7: CALIBRATION
# ============================================
print("ðŸ“ Step 7: Calibrating probabilities...")
print("-" * 80)

calibrator = CalibratedClassifierCV(meta_classifier, cv=3, method='isotonic')
calibrator.fit(X_meta_train, y_train)

calibrated_score = calibrator.score(X_meta_test, y_test)
print(f"âœ… Calibrated accuracy: {calibrated_score:.4f}")
print()

# ============================================
# STEP 8: SAVE MODELS
# ============================================
print("ðŸ’¾ Step 8: Saving models...")
print("-" * 80)

OUTPUT_DIR = "live_demo_1h/models"
os.makedirs(OUTPUT_DIR, exist_ok=True)

timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
schema_hash = "d7a9e9fb3a42"  # Same as 5m to indicate compatible features

# Save meta-classifier
meta_file = f'meta_classifier_{timestamp}_{schema_hash}.joblib'
joblib.dump(meta_classifier, os.path.join(OUTPUT_DIR, meta_file))
print(f"âœ… Saved: {meta_file}")

# Save calibrator
cal_file = f'calibrator_{timestamp}_{schema_hash}.joblib'
joblib.dump(calibrator, os.path.join(OUTPUT_DIR, cal_file))
print(f"âœ… Saved: {cal_file}")

# Save feature columns (in the format the bot expects)
feat_file = f'feature_columns_{timestamp}_{schema_hash}.json'
feature_schema = {
    "feature_cols": feature_columns,
    "schema_hash": schema_hash
}
with open(os.path.join(OUTPUT_DIR, feat_file), 'w') as f:
    json.dump(feature_schema, f)
print(f"âœ… Saved: {feat_file}")

# Save training metadata
metadata = {
    'timestamp_utc': timestamp,
    'target': 'direction_confidence_1h',
    'n_features': len(feature_columns),
    'schema_hash': schema_hash,
    'class_mapping': {'down': 0, 'neutral': 1, 'up': 2},
    'meta_score_in_sample': float(meta_score),
    'calibrated_score': float(calibrated_score),
    'cv_scores': cv_scores,
    'folds': 3,
    'embargo_pct': 0.01,
    'purge_pct': 0.02,
    'training_samples': len(X_train),
    'test_samples': len(X_test)
}

meta_meta_file = f'training_meta_{timestamp}_{schema_hash}.json'
with open(os.path.join(OUTPUT_DIR, meta_meta_file), 'w') as f:
    json.dump(metadata, f, indent=2)
print(f"âœ… Saved: {meta_meta_file}")

# Create LATEST.json
latest = {
    'meta_classifier': meta_file,
    'calibrator': cal_file,
    'feature_columns': feat_file,
    'training_meta': meta_meta_file
}

with open(os.path.join(OUTPUT_DIR, 'LATEST.json'), 'w') as f:
    json.dump(latest, f, indent=2)
print(f"âœ… Saved: LATEST.json")

print()
print("=" * 80)
print("ðŸŽ‰ 1H MODEL RETRAINED SUCCESSFULLY!")
print("=" * 80)
print()
print(f"ðŸ“Š Performance Summary:")
print(f"   Meta-classifier accuracy: {meta_score:.4f} ({meta_score*100:.2f}%)")
print(f"   Calibrated accuracy: {calibrated_score:.4f} ({calibrated_score*100:.2f}%)")
print(f"   Training samples: {len(X_train)}")
print(f"   Test samples: {len(X_test)}")
print(f"   Features: {len(feature_columns)} (matching live bot)")
print()
print("âœ… Model now uses the EXACT features the live bot expects!")
print("âœ… No more feature mismatch errors!")
print()
print("Next steps:")
print("1. Restart the 1h bot: python run_1h.py")
print("2. Bot should now work without errors")
print("3. Monitor for data collection")
print()
print("=" * 80)
